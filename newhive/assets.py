from os.path import dirname, join, abspath, normpath
import os
import json
from boto.s3.key import Key as S3Key
from boto.s3.connection import S3Connection
from newhive import config
from newhive.manage import git
from newhive.utils import lget, now
from md5 import md5


class Assets:
    def __init__(self, asset_path):
        self.base_path = normpath(join(config.src_home, asset_path))
        self.assets = {}

        self.s3_con = S3Connection(config.aws_id, config.aws_secret)
        self.asset_bucket = self.s3_con.create_bucket(config.asset_bucket)
        bucket_url = self.asset_bucket.generate_url(0)
        self.base_url = bucket_url[0:bucket_url.index('?')]

    # return (path, name) tuples
    def find(self, recurse=True, *opt_start_path):
        start_path = lget(opt_start_path, 0, '')
        strip = len(self.base_path) + 1
        
        for dirname, subdirs, filenames in os.walk(join(self.base_path, start_path)):
            if not recurse: subdirs[:] = [] # slice prevents subdirs being clobbered with new list
            for n in filenames:
                path = join(dirname, n)
                name = path[strip:]
                with open(path) as f: version = md5(f.read()).hexdigest()[:8]
                self.assets[name] = (path, version)
        self.assets[''] = (None, '') # hack to include empty asset name pointing to base_url

        return self

    # upload each asset
    def push_s3(self):
        versions_key_name = '.versions.json'
        versions_key = self.asset_bucket.get_key(versions_key_name)
        old_versions = json.loads(versions_key.get_contents_as_string()) if versions_key else {}
        if not versions_key:
            versions_key = S3Key(self.asset_bucket)
            versions_key.name = versions_key_name

        for name, (path, version) in self.assets.iteritems():
            if not path: continue
            if version != old_versions.get(name):
                print 'uploading: '+ name
                k = S3Key(self.asset_bucket)
                k.name = name
                # assets expire 10 years from now (we rely on cache busting query string)
                k.set_contents_from_filename(path, headers={'Cache-Control': 'max-age=' + str(86400 * 3650) })
                k.make_public()

        new_versions = dict([(r[0], r[1][1]) for r in self.assets.iteritems()]) # make name: version dict
        versions_key.set_contents_from_string(json.dumps(new_versions))

        return self

    def url(self, name):
        props = self.assets.get(name)
        # TODO: return path of special logging 404 page if asset not found
        if not props: return '/not_found:' + name
        path = self.base_url + name
        return path + '?' + props[1] if props[1] else ''

    def write_ruby(self, write_path):
        with open(join(config.src_home, write_path), 'w') as f:
            f.write(
                  '# Hey!\n'
                + '# This file is automatically generated by newhive.assets.Assets.write_ruby on server start\n\n'
                + 'Paths = {\n'
            )

            for name in self.assets:
                f.write('    "'+ name + '" => "' + self.url(name) + '",\n')

            f.write('}')
    
    def write_js(self, write_path):
        urls = dict([(name, self.url(name)) for name in self.assets])
        with open(join(config.src_home, write_path), 'w') as f:
            f.write(
                  '// Hey!\n'
                + '// This file is automatically generated by newhive.assets.Assets.write_js on server start\n\n'
                + 'var hive_asset_paths = ' + json.dumps(urls) +';'
            )
